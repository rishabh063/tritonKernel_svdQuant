{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145842b0-8594-4357-8abc-281da543cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ['TRITON_INTERPRET'] = '1' \n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9629bad-4c0d-4b9d-bc3c-faa6b70ce05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def grouped_matmul_k(\n",
    "    x_ptr, l1_ptr, xl1_ptr,x_quant_ptr , scale_ptr,\n",
    "    m,n,k,\n",
    "    bm: tl.constexpr, bn: tl.constexpr, bk: tl.constexpr, group_sz: tl.constexpr , bk_quant: tl.constexpr , group_size: tl.constexpr\n",
    "):\n",
    "    \n",
    "    #mat mul \n",
    "    pid_m = tl.program_id(0)\n",
    "    pid_n = tl.program_id(1)\n",
    "    num_pid_m, num_pid_n = tl.num_programs(0), tl.num_programs(1)\n",
    "    pid_m_new , pid_n_new=tl.swizzle2d(pid_m, pid_n, num_pid_m, num_pid_n, group_sz)  # Weirdness: tl.swizzle2d doesn't work when simulating on CPU\n",
    "    # pid_m_new , pid_n_new=pid_m,pid_n\n",
    "\n",
    "    acc = tl.zeros((bm, bn), dtype=tl.float32)\n",
    "    x_ptr_offset=k*(pid_m_new*bm + tl.expand_dims(tl.arange(0,bm), 1))+ tl.expand_dims(tl.arange(0,bk), 0)\n",
    "    l1_ptr_offset=(pid_n_new*bn+tl.expand_dims(tl.arange(0,bn), 0))+tl.expand_dims(tl.arange(0,bk), 1)*n\n",
    "    x_ptr_mask=k*tl.expand_dims(pid_m_new*bm+tl.arange(1,bm+1),1)\n",
    "    x_ptr_mask=tl.where(x_ptr_mask<m*k , x_ptr_mask , m*k)\n",
    "    l1_mask=(k-1)*n+pid_n_new*bn+tl.expand_dims(tl.arange(1,bn+1), 0)\n",
    "    l1_mask=tl.where(l1_mask<k*n , l1_mask , k*n)\n",
    "    for i in range ( 0 , tl.cdiv(k , bk)):\n",
    "        # print(i,l1_ptr_offset)\n",
    "        x_loaded=tl.load(x_ptr+x_ptr_offset ,x_ptr_offset<x_ptr_mask ,0)\n",
    "        l1_loaded=tl.load(l1_ptr+l1_ptr_offset ,l1_ptr_offset<l1_mask ,0)\n",
    "        acc += tl.dot(x_loaded, l1_loaded)\n",
    "        x_ptr_offset+=bk\n",
    "        l1_ptr_offset+=n*bk\n",
    "    xl1_offset=n*(pid_m_new*bm + tl.expand_dims(tl.arange(0,bm), 1))+ pid_n_new*bn+tl.expand_dims(tl.arange(0,bn), 0)\n",
    "    xl1_mask=n*(pid_m_new*bm + tl.expand_dims(tl.arange(0,bm), 1)+1)\n",
    "    acc=acc.to(tl.float16)\n",
    "    tl.store(xl1_ptr+xl1_offset , acc , xl1_offset<xl1_mask)\n",
    "\n",
    "    #quant\n",
    "    xptr_quant_start_point=k*(pid_m_new*bm + tl.expand_dims(tl.arange(0,bm), 1))+ pid_n_new*bk_quant\n",
    "    x_ptr_quant_offset_1=xptr_quant_start_point + 2*tl.expand_dims(tl.arange(0,group_size), 0)\n",
    "    x_ptr_quant_offset_2=xptr_quant_start_point + 2*tl.expand_dims(tl.arange(0,group_size), 0)+1\n",
    "    x_ptr_quant_mask=k*tl.expand_dims(pid_m_new*bm+tl.arange(1,bm+1),1)\n",
    "    x_ptr_quant_mask=tl.where(x_ptr_quant_mask<m*k , x_ptr_quant_mask , m*k)\n",
    "    \n",
    "    x_quant_store_offset=tl.cdiv(k,2)*(pid_m_new*bm + tl.expand_dims(tl.arange(0,bm), 1))+pid_n_new*bk_quant+tl.expand_dims(tl.arange(0,group_size), 0)\n",
    "    x_quant_store_mask=tl.cdiv(k,2)*(pid_m_new*bm + tl.expand_dims(tl.arange(0,bm), 1)+1)\n",
    "    \n",
    "    scale_quant_store_offset=tl.cdiv(k,2*group_size)*(pid_m_new*bm + tl.expand_dims(tl.arange(0,bm), 1))+pid_n_new*bk_quant\n",
    "    scale_quant_store_mask=tl.cdiv(k,(2*group_size))*(pid_m_new*bm + tl.expand_dims(tl.arange(0,bm), 1)+1)\n",
    "    if pid_n_new==0:\n",
    "        for i in range ( 0,tl.cdiv(k , 2*group_size)):\n",
    "            x_loaded_1=tl.load(x_ptr+x_ptr_quant_offset_1 ,x_ptr_quant_offset_1<x_ptr_quant_mask ,0)\n",
    "            x_loaded_2=tl.load(x_ptr+x_ptr_quant_offset_2 ,x_ptr_quant_offset_2<x_ptr_quant_mask ,0)\n",
    "            max_val_1=tl.max(tl.abs(x_loaded_1) , axis=1 , keep_dims=True)\n",
    "            max_val_2=tl.max(tl.abs(x_loaded_2) , axis=1 , keep_dims=True)\n",
    "            max_val=tl.where(max_val_1>max_val_2 , max_val_1 , max_val_2)\n",
    "            scale = 7.0 / (max_val + 1e-6)\n",
    "            scaled_1 = x_loaded_1 * scale\n",
    "            scaled_2 = x_loaded_2 * scale\n",
    "            clamped_vals_1 = tl.clamp(scaled_1, -8.0, 7.0)\n",
    "            clamped_vals_2 = tl.clamp(scaled_2, -8.0, 7.0)\n",
    "            int4_vals_1 = tl.where(clamped_vals_1 >= 0,\n",
    "                                 tl.floor(clamped_vals_1 + 0.5),\n",
    "                                 tl.ceil(clamped_vals_1 - 0.5)).to(tl.int8)\n",
    "                \n",
    "            int4_vals_2 = tl.where(clamped_vals_2 >= 0,\n",
    "                                 tl.floor(clamped_vals_2 + 0.5),\n",
    "                                 tl.ceil(clamped_vals_2 - 0.5)).to(tl.int8)\n",
    "            int8block = int4_vals_1 & 0x0F  # Lower 4 bits\n",
    "            int8block2 = int4_vals_2 & 0x0F  # Upper 4 bits\n",
    "            packed = (int8block2.to(tl.int8) << 4) | int8block.to(tl.int8)\n",
    "            packed=packed.to(tl.int8)\n",
    "            tl.store(x_quant_ptr +x_quant_store_offset,packed  , x_quant_store_offset<x_quant_store_mask)\n",
    "            tl.store(scale_ptr+scale_quant_store_offset ,max_val ,  scale_quant_store_offset<scale_quant_store_mask)\n",
    "    \n",
    "            x_ptr_quant_offset_1+=2*group_size\n",
    "            x_ptr_quant_offset_2+=2*group_size\n",
    "            x_quant_store_offset+=group_size\n",
    "            scale_quant_store_offset+=1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "360ba74b-e1ed-4096-8f68-21278ef23a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdiv(a,b):\n",
    "    return (a+b-1) //b\n",
    "def matmul(x1, l1):\n",
    "    assert x1.shape[1] == l1.shape[0], \"k should be same \"\n",
    "\n",
    "    m=x1.shape[0]\n",
    "    n=l1.shape[1]\n",
    "    k=l1.shape[0]\n",
    "\n",
    "    batch_size=16\n",
    "    half_quant_group_size=32\n",
    "    bk_quant=max(half_quant_group_size*2 , cdiv(k*batch_size,max(n , batch_size)))\n",
    "    grid = lambda meta: (triton.cdiv(m, meta['bm']),  triton.cdiv(n, meta['bn']))\n",
    "    xl1 = torch.empty((m, n), dtype=torch.float16).cuda().contiguous()\n",
    "    x1_quant = torch.zeros((m, cdiv(k,2)), dtype=torch.int8).cuda().contiguous()\n",
    "    x1_quant_scale=torch.zeros((m, cdiv(k,half_quant_group_size*2)), dtype=torch.float16).cuda().contiguous()\n",
    "\n",
    "    # print(x1_quant_scale.shape , bk_quant)\n",
    "    xl1 = torch.empty((m, n), dtype=torch.float16).cuda().contiguous()\n",
    "    # Launch kernel\n",
    "    \n",
    "    grouped_matmul_k[grid](\n",
    "        x_ptr=x1,l1_ptr=l1,xl1_ptr=xl1,\n",
    "        \n",
    "        x_quant_ptr=x1_quant , scale_ptr=x1_quant_scale,\n",
    "        \n",
    "        m=m,n=n,k=k,\n",
    "        bm=batch_size , bn=batch_size , bk=batch_size , group_sz=batch_size , bk_quant=bk_quant,group_size=half_quant_group_size\n",
    "    )\n",
    "    return xl1 , x1_quant , x1_quant_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85833228-0ec5-4161-b878-3735bd2b9383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you rock\n",
      "tensor(0.0078, device='cuda:0', dtype=torch.float16)\n",
      "tensor(-1.7881e-07, device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "m,r,k=160 , 128, 620\n",
    "x1 = torch.randn((m, k),dtype=torch.float16).cuda().contiguous()\n",
    "l1 = torch.randn((k, r), dtype=torch.float16).cuda().contiguous()\n",
    "\n",
    "triton_output , triton_quant ,x1_quant_scale =matmul(x1,l1)\n",
    "torch_output=x1@l1\n",
    "if torch.allclose(triton_output, torch_output, atol=5e-2, rtol=0):\n",
    "    print('you rock')\n",
    "else:\n",
    "    print(\"âŒ Triton and Torch differ\")\n",
    "\n",
    "\n",
    "print(torch.max(triton_output-torch_output))\n",
    "print(torch.mean(triton_output-torch_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be551abe-29f7-4231-86f6-47d2c0ef95ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1660, 2.7773, 2.6387,  ..., 2.4297, 2.1875, 1.6777],\n",
       "        [2.6484, 2.4004, 2.5938,  ..., 3.4727, 2.7715, 2.7930],\n",
       "        [2.4102, 2.5664, 2.7480,  ..., 2.2910, 2.9023, 3.2246],\n",
       "        ...,\n",
       "        [2.6152, 2.4766, 3.0020,  ..., 3.4102, 2.5996, 2.5664],\n",
       "        [2.7988, 1.9678, 2.8809,  ..., 2.0430, 2.3379, 2.6367],\n",
       "        [2.9902, 2.6641, 2.5430,  ..., 2.6621, 2.6309, 3.6484]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_quant_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "771fe875-cb43-4a6c-9b36-694a456df8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "def grouped_matmul_quant_pytorch(x1, l1, group_size=32):\n",
    "    \"\"\"\n",
    "    Performs matrix multiplication and quantizes x1 in PyTorch.\n",
    "    \n",
    "    Args:\n",
    "        x1 (torch.Tensor): Input tensor of shape (m, k), dtype float\n",
    "        l1 (torch.Tensor): Weight tensor of shape (k, n), dtype float\n",
    "        group_size (int): Number of elements per quantization group (default: 32)\n",
    "    \n",
    "    Returns:\n",
    "        xl1 (torch.Tensor): Result of x1 @ l1, shape (m, n)\n",
    "        x1_quant (torch.Tensor): Quantized x1, shape (m, ceil(k / 2)), dtype int8\n",
    "        scales (torch.Tensor): Scales per group, shape (m, ceil(k / (2 * group_size)))\n",
    "    \"\"\"\n",
    "    m, k = x1.shape\n",
    "    _, n = l1.shape\n",
    "    device = x1.device\n",
    "    assert x1.shape[1] == l1.shape[0], \"k dimensions must match for matrix multiplication\"\n",
    "\n",
    "    # 1. Matrix Multiplication\n",
    "    xl1 = torch.matmul(x1, l1)\n",
    "\n",
    "    # 2. Quantization of x1\n",
    "    # Number of groups per row\n",
    "    num_groups = math.ceil(k / (2 * group_size))\n",
    "    padded_k = num_groups * 2 * group_size\n",
    "\n",
    "    # Pad x1 to a multiple of 2 * group_size along the k dimension\n",
    "    x1_padded = torch.nn.functional.pad(x1, (0, padded_k - k), mode='constant', value=0)\n",
    "    # Reshape into (m, num_groups, 2 * group_size)\n",
    "    x1_groups = x1_padded.view(m, num_groups, 2 * group_size)\n",
    "\n",
    "    # Compute maximum absolute value per group\n",
    "    max_vals = torch.max(torch.abs(x1_groups+1e-6), dim=2).values  # Shape: (m, num_groups)\n",
    "    scales = 7.0 / (max_vals + 1e-6)                   # Shape: (m, num_groups)\n",
    "\n",
    "    # Scale and clamp\n",
    "    scaled = x1_groups * scales.unsqueeze(2)           # Shape: (m, num_groups, 2 * group_size)\n",
    "    clamped = torch.clamp(scaled, -8.0, 7.0)\n",
    "\n",
    "    # Round to nearest integer, with ties rounding away from zero\n",
    "    rounded = torch.where(\n",
    "        clamped >= 0,\n",
    "        torch.floor(clamped + 0.5),\n",
    "        torch.ceil(clamped - 0.5)\n",
    "    )\n",
    "    int8_vals = rounded.to(torch.int8)                 # Shape: (m, num_groups, 2 * group_size)\n",
    "\n",
    "    # Trim to original k and prepare for packing\n",
    "    q_vals = int8_vals.view(m, -1)[:, :k]              # Shape: (m, k)\n",
    "    num_pairs = k // 2\n",
    "    x1_quant = torch.zeros((m, math.ceil(k / 2)), dtype=torch.int8, device=device)\n",
    "\n",
    "    # Pack pairs of int4 values into int8\n",
    "    if num_pairs > 0:\n",
    "        q0 = q_vals[:, 0:2*num_pairs:2]                # Even indices\n",
    "        q1 = q_vals[:, 1:2*num_pairs:2]                # Odd indices\n",
    "        packed_pairs = (\n",
    "            (torch.bitwise_and(q1, 0x0F).to(torch.uint8) << 4) |\n",
    "            torch.bitwise_and(q0, 0x0F).to(torch.uint8)\n",
    "        )\n",
    "        x1_quant[:, :num_pairs] = packed_pairs.to(torch.int8)\n",
    "    if k % 2 == 1:\n",
    "        q_last = q_vals[:, -1]\n",
    "        x1_quant[:, -1] = torch.bitwise_and(q_last, 0x0F).to(torch.uint8)\n",
    "\n",
    "    return xl1, x1_quant, max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bc91682-0baf-4e2b-8f88-8b70c304d620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton average time: 0.001160 seconds\n",
      "PyTorch average time: 0.000438 seconds\n",
      "Matrix multiplication matches: False\n",
      "Quantized values match: False\n",
      "Scales match: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import triton\n",
    "import time\n",
    "\n",
    "# Your Triton matmul function (assumed to be defined as in the query)\n",
    "# def matmul(x1, l1): ...  # Returns xl1, x1_quant, x1_quant_scale\n",
    "\n",
    "# Test parameters\n",
    "m, k, n = 400,624, 400\n",
    "group_size = 32\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Generate random inputs\n",
    "x1 = torch.randn(m, k, dtype=torch.float16, device=device)\n",
    "l1 = torch.randn(k, n, dtype=torch.float16, device=device)\n",
    "\n",
    "# Warm-up runs\n",
    "for _ in range(10):\n",
    "    matmul(x1, l1)\n",
    "    grouped_matmul_quant_pytorch(x1, l1, group_size)\n",
    "\n",
    "# Time Triton kernel\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    xl1_triton, x1_quant_triton, scales_triton = matmul(x1, l1)\n",
    "torch.cuda.synchronize()\n",
    "triton_time = (time.time() - start) / 100\n",
    "print(f\"Triton average time: {triton_time:.6f} seconds\")\n",
    "\n",
    "# Time PyTorch implementation\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    xl1_pytorch, x1_quant_pytorch, scales_pytorch = grouped_matmul_quant_pytorch(x1, l1, group_size)\n",
    "torch.cuda.synchronize()\n",
    "pytorch_time = (time.time() - start) / 100\n",
    "print(f\"PyTorch average time: {pytorch_time:.6f} seconds\")\n",
    "\n",
    "# Verify correctness (optional)\n",
    "print(\"Matrix multiplication matches:\", torch.allclose(xl1_triton.float(), xl1_pytorch.float(), atol=5e-2, rtol=0))\n",
    "print(\"Quantized values match:\", torch.allclose(x1_quant_triton.float(), x1_quant_pytorch.float(), atol=5e-2, rtol=0))\n",
    "print(\"Scales match:\", torch.allclose(scales_triton.float(), scales_pytorch.float(), atol=5e-2, rtol=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d07cee-fe67-4bbb-854f-c6d3156b9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.mean(xl1_triton.float()))\n",
    "print(torch.mean(xl1_triton.float()))\n",
    "print(torch.mean(xl1_triton.float()-xl1_pytorch.float()))\n",
    "print(torch.max(xl1_triton.float()-xl1_pytorch.float()))\n",
    "xl1_triton.float()-xl1_pytorch.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b0c5c-2371-4f4a-ac7b-ccf4a46161b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=\n",
    "x1_quant_pytorch.float()-x1_quant_triton.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55575b21-ea27-412b-8b9e-dc6d8b0e0d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales_triton[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2aea1b-a08f-47cb-a6ca-6ce263133861",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_Values = x1_quant_triton & 0x0F  # 0 , 2 , 4 , 8 ..\n",
    "odd_Values = (x1_quant_triton >> 4) & 0x0F  # 1 , 2 , 3 , 4 ....\n",
    "x1quant_raw=merge_even_odd(even_Values , odd_Values , m , k) \n",
    "x1quant_raw=torch.where(x1quant_raw<8 , x1quant_raw , x1quant_raw-16)\n",
    "expanded_scale=expand_scale(scales_triton , m , k , 32)\n",
    "x1quant=x1quant_raw * (expanded_scale/7.0  )\n",
    "# print(expanded_scale[-1]/7.0)\n",
    "i=9\n",
    "j=15\n",
    "print((x1quant[j][64*i:64*(i+1)] - x1[j][64*i:64*(i+1)])<scales_triton[j][i]/7)\n",
    "print(x1_quant_pytorch.float()[j][32*i:32*(i+1)]-x1_quant_triton.float()[j][32*i:32*(i+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee731d-2623-4ac7-b420-aaf8698bd05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_quant_pytorch.float()[j][64*i:64*(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2012216-23ac-4ceb-ad6e-c0368ecfe167",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales_pytorch[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20c8733-ea92-4632-80c9-dea924110d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(x1[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0fd44e-7dac-4535-a913-be1d813319c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a210bc5-14c7-4ef5-8c1f-c0fd6fa82c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4b367-196e-4bf7-84e7-1714e439cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_even_odd(even_Values, odd_Values, m, k):\n",
    "    \n",
    "    device = even_Values.device\n",
    "    dtype = even_Values.dtype\n",
    "    \n",
    "    \n",
    "    merged = torch.zeros((m, k), dtype=dtype, device=device)\n",
    "    \n",
    "    \n",
    "    merged[:, 0::2] = even_Values  # Even indices\n",
    "    \n",
    "    merged[:, 1::2] = odd_Values   # Odd indices\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def expand_scale(x1_quant_scale, m, k, group_size):\n",
    "\n",
    "    num_groups = x1_quant_scale.shape[1]  # k//(2*group_size)\n",
    "    # Reshape to (m, num_groups, 1) and repeat across 2*group_size elements\n",
    "    scale_expanded = x1_quant_scale.unsqueeze(-1).repeat(1, 1, 2 * group_size)\n",
    "    # Flatten to (m, k), trimming excess if k is not perfectly divisible\n",
    "    scale_expanded = scale_expanded.reshape(m, -1)[:, :k]\n",
    "    return scale_expanded\n",
    "    \n",
    "\n",
    "even_Values = triton_quant & 0x0F  # 0 , 2 , 4 , 8 ..\n",
    "odd_Values = (triton_quant >> 4) & 0x0F  # 1 , 2 , 3 , 4 ....\n",
    "x1quant=merge_even_odd(even_Values , odd_Values , m , k) \n",
    "x1quant=torch.where(x1quant<8 , x1quant , x1quant-16)\n",
    "expanded_scale=expand_scale(x1_quant_scale , m , k , 32)\n",
    "x1quant=x1quant * (expanded_scale/7.0  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6fdeb0-b530-4be2-8261-c331999a8bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1quant[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fcb1a6-ae42-4b79-a4c1-1d88fbb17e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada1a2a-d6c7-4e60-a4bb-65fab7102674",
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_quant.shape , m , k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e4784e-ebfd-4fde-b373-8ad279dfdf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_quant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280061f3-f20d-40d3-892c-2f79c77f84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e88290-187c-46fc-aae3-8f198e2959ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_quant_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7acf6-e4ea-42f5-8057-177ee5c3e3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c17c8-abef-4632-bfc8-a035c7ae1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.max(triton_output-torch_output))\n",
    "print(torch.mean(triton_output-torch_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc2438e-b9ae-4e47-af0b-724626f703c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for i in range(0,100):\n",
    "    point1=random.randint(0,m-1)\n",
    "    point2=random.randint(0,r-1)\n",
    "    print(triton_output[point1][point2])\n",
    "    print(torch_output[point1][point2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ece45-4313-4ffd-84b5-e56fc83369cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf064806-d49b-4b2b-a5ae-6ed688abe193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
